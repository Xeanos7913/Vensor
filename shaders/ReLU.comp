#version 450
#extension GL_ARB_separate_shader_objects : enable
#extension GL_EXT_buffer_reference : enable
#extension GL_EXT_buffer_reference_uvec2 : enable
#extension GL_EXT_scalar_block_layout : enable

// Workgroup size (runtime specialization constants)
layout(local_size_x_id = 0, local_size_y_id = 1, local_size_z_id = 2) in;

layout(buffer_reference, std430, scalar) buffer tensor_data {
    float data[];
};

layout(buffer_reference, std430, scalar) buffer tensor_grad {
    float grad[];
};

layout(buffer_reference, std430, scalar) buffer tensor_strides {
    int strides[];
};

layout(buffer_reference, std430, scalar) buffer tensor_shape {
    int dims[];
};

struct TensorImpl {
    tensor_data    data;
    tensor_grad    grad;
    tensor_strides strides;
    tensor_shape   shape;
    uint numel;
    uint ndim;
    uint requires_grad;
    uint is_leaf;
};

struct ReLUcontext {
    TensorImpl input_tensor;
    TensorImpl output_tensor;
    uint M, N;
    uint batch_size;         // Total batch size for gradient averaging
    uint mode;              // 0 = in-place, 1 = out-of-place
    uint accumulate_grad;   // 0: overwrite, 1: += for grads
};

layout(buffer_reference, std430, buffer_reference_align = 16) buffer ContextBuffer {
    ReLUcontext ctx;
};

layout(push_constant) uniform PushConstants {
    ContextBuffer context;   // host must match std430 layout
    uvec3 grid_size;         // number of workgroups dispatched (gl_NumWorkGroups)
    uint  kernel_type;       // 0 = forward, 1 = backward (compute dInput)
} push;

// Compute linear index into a C-contiguous tensor from up to 3 indices using supplied strides.
uint off2or3(const TensorImpl t, uint b, uint i, uint j)
{
    if (t.ndim == 2u) {
        return i * t.strides.strides[0] + j * t.strides.strides[1];
    } else {
        return b * t.strides.strides[0] + i * t.strides.strides[1] + j * t.strides.strides[2];
    }
}

void relu_forward() {
    ReLUcontext c = push.context.ctx;
    uint bx = gl_WorkGroupID.x;  
    uint by = gl_WorkGroupID.y;  
    uint bz = gl_WorkGroupID.z;  
    uint lx = gl_LocalInvocationID.x;  
    uint ly = gl_LocalInvocationID.y;  
    uint b = bz;  
    uint row = by * gl_WorkGroupSize.y + ly; // in [0..M)  
    uint col = bx * gl_WorkGroupSize.x + lx; // in [0..N)  
    uint M = c.M;
    uint N = c.N;
    
    // Early exit for threads that are completely out of bounds  
    if (row >= M || col >= N) {  
        return;  
    }
    
    uint inIdx = off2or3(c.input_tensor, b, row, col);
    uint outIdx = off2or3(c.output_tensor, b, row, col);
    
    // Forward: out = max(0, in)
    float inputValue = c.input_tensor.data.data[inIdx];
    c.output_tensor.data.data[outIdx] = max(0.0, inputValue);
}

void main() {
    relu_forward();
}