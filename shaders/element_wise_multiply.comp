#version 450
#extension GL_ARB_separate_shader_objects : enable
#extension GL_EXT_buffer_reference : enable
#extension GL_EXT_buffer_reference_uvec2 : enable
#extension GL_EXT_scalar_block_layout : enable
#extension GL_EXT_shader_atomic_float : enable

layout(local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

layout(buffer_reference, std430, scalar) buffer tensor_data {
    float data[];
};
layout(buffer_reference, std430, scalar) buffer tensor_grad {
    float grad[];
};
layout(buffer_reference, std430, scalar) buffer tensor_strides {
    int strides[];
};
layout(buffer_reference, std430, scalar) buffer tensor_shape {
    int dims[];
};

struct TensorImpl {
    tensor_data    data;
    tensor_grad    grad;
    tensor_strides strides;
    tensor_shape   shape;
    uint numel, ndim, requires_grad, is_leaf;
};

struct ElementWiseMultiply {
    TensorImpl input_a;   // output tensor (result stored here)
    TensorImpl input_b;   // input tensor to multiply
    uint mode;            // 0 = tiled, 1 = simple
    uint batch_size;
    uint m, n;
    uint accumulate_grad; // 0: overwrite, 1: += for grads
};

layout(buffer_reference, std430, buffer_reference_align = 16) buffer ContextBuffer { 
    ElementWiseMultiply ctx; 
};

layout(push_constant) uniform PushConstants {
    ContextBuffer context;
    uvec3 grid_size;
    uint  kernel_type; // 0=forward, 1=backward
} push;

// Convert flat index to multi-dimensional indices
void unravel_index(uint flat_idx, TensorImpl tensor, out int indices[8]) {
    uint remaining = flat_idx;
    for (int i = int(tensor.ndim) - 1; i >= 0; i--) {
        indices[i] = int(remaining % uint(tensor.shape.dims[i]));
        remaining /= uint(tensor.shape.dims[i]);
    }
}

// Convert multi-dimensional indices to flat index with broadcasting
uint ravel_index_with_broadcast(int indices[8], TensorImpl tensor, uint output_ndim) {
    uint flat_idx = 0;
    
    // Handle broadcasting: align dimensions from the right
    int offset = int(output_ndim) - int(tensor.ndim);
    
    for (int i = 0; i < int(tensor.ndim); i++) {
        int output_dim_idx = offset + i;
        int idx = indices[output_dim_idx];
        
        // If this dimension is 1, broadcast (use index 0)
        if (tensor.shape.dims[i] == 1) {
            idx = 0;
        }
        
        flat_idx += uint(idx * tensor.strides.strides[i]);
    }
    
    return flat_idx;
}

void main() {
    uint gid = gl_GlobalInvocationID.x;
    ElementWiseMultiply op = push.context.ctx;
    
    // Check bounds
    if (gid >= op.input_a.numel) {
        return;
    }
    
    // Determine the output shape (use input_a as reference)
    uint output_ndim = op.input_a.ndim;
    
    // Convert global index to multi-dimensional indices based on output shape
    int indices[8];
    unravel_index(gid, op.input_a, indices);
    
    // Get flat indices for both tensors with broadcasting
    uint idx_a = gid; // input_a is the output, no broadcasting needed
    uint idx_b = ravel_index_with_broadcast(indices, op.input_b, output_ndim);
    
    // Perform element-wise multiplication
    float val_a = op.input_a.data.data[idx_a];
    float val_b = op.input_b.data.data[idx_b];
    
    // Store result back to input_a (in-place operation: b = b * a)
    op.input_a.data.data[idx_a] = val_a * val_b;
}