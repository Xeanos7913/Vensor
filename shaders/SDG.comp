#version 450
#extension GL_ARB_separate_shader_objects : enable
#extension GL_EXT_buffer_reference : enable
#extension GL_EXT_buffer_reference_uvec2 : enable
#extension GL_EXT_scalar_block_layout : enable

// Workgroup size [dispatch = (cielDiv(num_elements, 256u), 1, 1)]
layout(local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

layout(buffer_reference, std430, buffer_reference_align = 16) buffer tensor_data {
    float data[];
};

layout(buffer_reference, std430, buffer_reference_align = 16) buffer tensor_grad {
    float grad[];
};

layout(buffer_reference, std430, buffer_reference_align = 16) buffer tensor_strides {
    int strides[];
};

layout(buffer_reference, std430, buffer_reference_align = 16) buffer tensor_shape {
    int dims[];
};

struct TensorImpl {
    tensor_data    data;
    tensor_grad    grad;
    tensor_strides strides;
    tensor_shape   shape;
    uint numel;
    uint ndim;
    uint requires_grad;
    uint is_leaf;
};

struct Uniform {
    TensorImpl tensor;
    float lr; // learning rate
    uint batch_size;
};

layout(buffer_reference, std430, buffer_reference_align = 16) buffer UniformBuffer {
    Uniform u;
};

layout(push_constant) uniform PushConstants {
    UniformBuffer ctx;
} push;

uint off2or3(const TensorImpl t, uint b, uint i, uint j) {
    if (t.ndim == 2u) {
        return i * t.strides.strides[0] + j * t.strides.strides[1];
    } else {
        return b * t.strides.strides[0] + i * t.strides.strides[1] + j * t.strides.strides[2];
    }
}

void main() {
    // Get global thread ID
    uint gid = gl_GlobalInvocationID.x;
    
    // Load uniform data
    Uniform u = push.ctx.u;
    TensorImpl tensor = u.tensor;
    
    // Bounds check
    if (gid >= tensor.numel) {
        return;
    }
    
    // Load current parameter value and gradient
    float param = tensor.data.data[gid];
    float gradient = tensor.grad.grad[gid];

    // SGD update: param = param - lr * gradient
    // If using mini-batches, average the gradient
    if (u.batch_size > 1u) {
        gradient /= float(u.batch_size);
    }

    // Clamp gradient to avoid exploding updates
    //gradient = clamp(gradient, -15.0, 15.0);

    float updated_param = param - u.lr * gradient;
    
    // Write back updated parameter
    tensor.data.data[gid] = updated_param;
    
    // Zero out gradient after update
    tensor.grad.grad[gid] = 0.0;
}